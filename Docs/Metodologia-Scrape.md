# üîß Metodologia Scrappy v3.0 - Transcri√ß√£o Inteligente Markdown

> **Atualiza√ß√£o:**

> **Diferencial:** Cada "quadradinho" fala estruturado, metadados completos DOM Grok

---

## üéØ Vis√£o Geral

**Objetivo:** Captar conversas Grok (`grok.com/share/*`) preservando **100% contexto conversacional** - quem falou, quando, dispositivo usado, estrutura hier√°rquica cada mensagem.

**Poder Agentico:** 

- ‚úÖ **Diferencia falantes:** Deivison vs Grok (marca√ß√£o clara cada bloco)

- ‚úÖ **Markdown estruturado:** Headers, blockquotes, listas - cada fala um "quadradinho"

- ‚úÖ **Metadados DOM:** Timestamp, dispositivo (mobile/desktop), dura√ß√£o conversa

- ‚úÖ **Naming inteligente:** Data + t√≥pico + diferencia√ß√£o autom√°tica duplicatas

- ‚úÖ **An√°lise contextual:** Sentimentos, corre√ß√µes, valida√ß√µes, erros modelo

**Casos de Uso:**

- 1 conversa ‚Üí 1 transcri√ß√£o MD estruturada completa

- M√∫ltiplas conversas ‚Üí pasta `Transcricoes/` organizada data/t√≥pico

- Atualiza√ß√£o docs ‚Üí detecta contexto pr√©vio, aplica delta

---

## üß† An√°lise Contextual Profunda

### Camadas de Processamento

**1. Capta√ß√£o Bruta (Playwright)**

- Extrai `innerText('body')` completo

- Preserva quebras de linha, espa√ßamento, estrutura original

- Timeout adaptativo (5-10s) baseado em tamanho da conversa

**2.

```text
"entendeu?" ‚Üí Marca ponto de confirma√ß√£o (usu√°rio valida compreens√£o IA)
"repete"    ‚Üí Marca solicita√ß√£o de reitera√ß√£o (poss√≠vel erro Grok)
"t√°, vamos l√°" ‚Üí Marca transi√ß√£o de contexto (novo t√≥pico)
[sil√™ncio Grok +

```text

**3. Extra√ß√£o de Sentimentos/Inclina√ß√µes**

- Tom emocional: frustra√ß√£o ("n√£o t√° certo"), satisfa√ß√£o ("perfeito"), d√∫vida ("acho que...")

- Prioridades impl√≠citas: palavras-chave como "urgente", "pendente", "cr√≠tico"

- Perspectivas: "na minha opini√£o", "acredito que", "seria interessante"

**4.

```javascript
// IA detecta afirma√ß√µes temporais suspeitas
if (mencao_data_modelo_desatualizada || info_2024_em_contexto_2025) {
  await webSearch(`${topico} atualiza√ß√£o 2025`);
  compara_e_corrige(info_modelo, info_web);
}

```text
**Exemplo:**

- Grok diz: "Ubuntu 20.04 √© a vers√£o mais recente" (desatualizado)

- IA pesquisa: "Ubuntu latest LTS 2025" ‚Üí Descobre 24.04 LTS

- Corre√ß√£o autom√°tica na transcri√ß√£o: "Ubuntu 24.04 LTS (atualizado via web)"

**5. Detec√ß√£o de Corre√ß√µes do Usu√°rio**

- "N√£o, n√£o √© assim" ‚Üí Marca nega√ß√£o de info pr√©via

- "Na verdade, s√£o 16 Positivo, n√£o Ryzen 7" ‚Üí Marca corre√ß√£o factual

- "Esquece isso" ‚Üí Marca anula√ß√£o de instru√ß√£o anterior

---

## üìÇ Estrutura Multi-Arquivo (Organiza√ß√£o Inteligente)

### Cen√°rio 1: Conversa √önica

```text
scrape.js (executa)
  ‚Üì
TRANSCRICAO-<data>.md (output final)

```text

### Cen√°rio 2: M√∫ltiplas Conversas (5 links)

```text
scrape-batch.js (executa 5 capta√ß√µes)
  ‚Üì
transcricoes/
‚îú‚îÄ‚îÄ 001-<uuid>.json      # JSON completo conversa 1

‚îú‚îÄ‚îÄ 002-<uuid>.json      # JSON completo conversa 2

‚îú‚îÄ‚îÄ 003-<uuid>.json      # ...

‚îú‚îÄ‚îÄ 004-<uuid>.json
‚îú‚îÄ‚îÄ 005-<uuid>.json
‚îî‚îÄ‚îÄ CONSOLIDADO-<data>.md  # Markdown unificado refatorado

```text

**Estrutura JSON Individual:**

```json
{
  "metadata": {
    "uuid": "5dac29e4-dcea-4578-bb58-70b3e699bdc9",
    "capturedAt": "2025-10-30T23:47:00Z",
    "linkOriginal": "https://grok.com/share/...",
    "duracao": "8.2s",
    "tamanho": "49847 bytes"
  },
  "contexto": {
    "documentoBase": "CATALOGACAO-UFRB-CETENS.md",
    "objetivo": "Edi√ß√£o linha a linha -

    "participantes": ["Deivison Santana", "Grok"]
  },
  "conversaRaw": "Texto bruto completo captado...",
  "analiseContextual": {
    "pontosConfirmacao": [
      { "linha": 45, "texto": "entendeu?", "resposta": "Entendi sim..." }
    ],
    "correcoes": [
      { "linha": 67, "original": "Ryzen 7", "corrigido": "Positivo", "contexto": "Lab 09" }
    ],
    "sentimentos": [
      { "tipo": "frustra√ß√£o", "trigger": "t√° um lix√£o", "contexto": "Lab LAMAV" }
    ],
    "errosGrok": [
      { "linha": 89, "descricao": "N√£o respondeu, usu√°rio continuou" }
    ]
  },
  "pendenciasExtraidas": [
    { "critica": "Sala 205 sem projetor", "contexto": "tem aulas" },
    { "media": "Refil Epson indispon√≠vel", "contexto": "Lab Agroecologia" }
  ],
  "instrucoesEdicao": [
    { "arquivo": "CATALOGACAO-UFRB-CETENS.md", "linha": 6, "acao": "remover", "conteudo": "95% mapeado" },
    { "arquivo": "CATALOGACAO-UFRB-CETENS.md", "linha": 456, "acao": "substituir", "de": "Ryzen 7", "para": "Positivo" }
  ]
}

```text

### Cen√°rio 3: Atualiza√ß√£o de Doc Existente

```text
IA l√™ doc atual ‚Üí Detecta contexto pr√©vio ‚Üí Aplica delta (s√≥ mudan√ßas)
N√£o reescreve tudo, apenas adiciona/corrige se√ß√µes alteradas

```text

---

## ‚öôÔ∏è Configura√ß√£o Playwright Otimizada (CLI-First)

```javascript
// scrape.js -

const { chromium } = require('playwright');

const GROK_LINK = process.argv[2] || 'https://grok.com/share/c2hhcmQtMg%3D%3D_5dac29e4...';

(async () => {
  const browser = await chromium.launch({
    headless: true, // Sem GUI = 3x mais r√°pido
    args: ['--no-sandbox', '--disable-gpu'] // Otimiza√ß√µes Linux
  });
  
  const page = await browser.newPage();
  await page.setExtraHTTPHeaders({
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'
  });
  
  console.log(`üì• Captando: ${GROK_LINK}`);
  await page.goto(GROK_LINK, { waitUntil: 'networkidle' }); // Mais preciso que timeout fixo
  
  const content = await page.innerText('body');
  console.log(content); // Output direto para pipe/arquivo
  
  await browser.close();
})();

```text

**Uso CLI:**

```bash

# Simples

node scrape.js "https://grok.com/share/..."

# Com pipe para arquivo

node scrape.js "link" > output.txt

# Multi-arquivo em batch

for link in $(cat links.txt); do
  node scrape.js "$link" > "transcricoes/$(uuidgen).txt"
done

```text

### Com GUI (Debug Visual)

```javascript
// scrape-debug.js -

const { chromium } = require('playwright');

(async () => {
  const browser = await chromium.launch({
    headless: false, // Abre GUI
    slowMo: 1000 // Delay 1s entre a√ß√µes (ver passo a passo)
  });
  
  const page = await browser.newPage();
  await page.goto('https://grok.com/share/...');
  
  // Mant√©m aberto
  await new Promise(() => {});
})();

```text

### Playwright via MCP (Se Dispon√≠vel)

```javascript
// Verifica se MCP Playwright est√° ativo
const hasMCP = process.env.MCP_PLAYWRIGHT_ENABLED;

if (hasMCP) {
  // Usa MCP nativo (mais r√°pido, compartilha contexto)
  const result = await mcp.playwright.navigate(GROK_LINK);
  console.log(result.text);
} else {
  // Fallback para Playwright padr√£o
  // ... c√≥digo acima
}

```text

---

## üéØ Workflow Completo (Atualizado)

### Conversa √önica

```mermaid
graph TD
    A[Link Grok] --> B[scrape.js]
    B --> C{An√°lise IA}
    C --> D[Detecta padr√µes]
    C --> E[Web research]
    C --> F[Extrai corre√ß√µes]
    D --> G[JSON estruturado]
    E --> G
    F --> G
    G --> H[Markdown final]

```text

### M√∫ltiplas Conversas (Batch)

```bash
#!/bin/bash

# scrape-batch.sh

mkdir -p transcricoes
LINKS=(
  "https://grok.com/share/link1"
  "https://grok.com/share/link2"
  "https://grok.com/share/link3"
)

for i in "${!LINKS[@]}"; do
  UUID=$(echo "${LINKS[$i]}" | grep -oP '(?<=_)[^/]+$')
  echo "üì• Captando conversa $((i+1))/${#LINKS[@]}..."
  node scrape.js "${LINKS[$i]}" > "transcricoes/${i}-${UUID}.txt"
done

echo "‚úÖ Capta√ß√µes conclu√≠das! Gerando JSONs +

node process-batch.js transcricoes/*.txt > CONSOLIDADO-$(date +%Y%m%d).md

```text

---

## üìö An√°lise Estrutura Grok (Testes Realizados)

### Descobertas (Atualizado 30/10/2025)

**Estrutura DOM:**

- Grok usa React (divs din√¢micos, sem IDs est√°veis)

- Bot√£o "Share" cria URL √∫nica imediatamente (sem precisar copiar)

- URL format: `grok.com/share/<base64>_<uuid>`

- Conte√∫do carrega via JS (aguardar ~5s ou `networkidle`)

**Seletores √öteis:**

```javascript
// Conversa completa (mais preciso que body.innerText)
const messages = await page.$$eval('[role="article"]', els => 
  els.map(el => ({
    author: el.querySelector('[data-author]')?.innerText,
    text: el.innerText,
    timestamp: el.querySelector('time')?.getAttribute('datetime')
  }))
);

// Metadados (se dispon√≠veis)
const title = await page.textContent('h1'); // T√≠tulo conversa
const date = await page.getAttribute('time', 'datetime'); // Data/hora

```text

---

## üîç Checklist P√≥s-Capta√ß√£o (Expandido)

### Valida√ß√£o T√©cnica

- [ ] Texto completo captado (sem truncamento)

- [ ] Encoding correto (UTF-8, emojis preservados)

- [ ] Metadados extra√≠dos (UUID, data, participantes)

- [ ] JSON estruturado salvo (se batch)

### An√°lise Contextual

- [ ] Pontos de confirma√ß√£o detectados ("entendeu?")

- [ ] Corre√ß√µes do usu√°rio identificadas

- [ ] Sentimentos/inclina√ß√µes mapeados

- [ ] Erros do Grok marcados (n√£o respondeu)

### Valida√ß√£o de Atualidade

- [ ] Afirma√ß√µes temporais verificadas via web

- [ ] Datas do modelo vs 2025 comparadas

- [ ] Tecnologias atualizadas (ex: Ubuntu 20.04 ‚Üí 24.04)

### Output Final

- [ ] Markdown principal atualizado (se single)

- [ ] Pasta `transcricoes/` criada (se batch)

- [ ] Redund√¢ncias eliminadas

- [ ] Links/refer√™ncias organizados

- [ ] Emojis contextuais aplicados

---

## üöÄ Melhorias Futuras (Roadmap)

### v2.1 (Pr√≥xima Itera√ß√£o)

- [ ] Detec√ß√£o autom√°tica de m√∫ltiplos links (ler de arquivo `.txt`)

- [ ] Diff autom√°tico (comparar com capta√ß√£o anterior, mostrar s√≥ mudan√ßas)

- [ ] Retry inteligente (se falhar, tenta 3x com backoff exponencial)

- [ ] Compress√£o JSON (salvar `.json.gz` para economizar espa√ßo)

### v2.2 (M√©dio Prazo)

- [ ] Integra√ß√£o Memory MCP (persistir contexto entre sess√µes)

- [ ] Web research autom√°tico em background (valida enquanto capta)

- [ ] An√°lise de sentimentos via NLP (sentiment.js ou API externa)

- [ ] Dashboard visual (mostrar m√©tricas: capta√ß√µes/dia, erros, tempo m√©dio)

### v3.0 (Longo Prazo)

- [ ] Capta√ß√£o em tempo real (WebSocket Grok, se API p√∫blica futura)

- [ ] Multi-idioma (detectar PT/EN/ES automaticamente)

- [ ] Versionamento de transcri√ß√µes (Git-like: diff, blame, rollback)

- [ ] Plugin VS Code (captar link direto da IDE)

---

## üìö Refer√™ncias e Recursos

### Documenta√ß√£o Oficial

- **Playwright:** [playwright.dev](https://playwright.dev) (v1.56.1 atual)

- **Grok AI:** [x.com/i/grok](https://x.com/i/grok) (compartilhamento de chats)

- **Node.js:** [nodejs.org](https://nodejs.org) (v24+ recomendado)

### Estudos de Caso

- **LinkedIn (2025):** "Grok's chat sharing feature makes conversations searchable" - An√°lise de como funciona o bot√£o "Share"

- **SEO Sherpa:** "When Grok Goes Public" - Casos de uso compartilhamento p√∫blico

- **Reddit r/grok:** Comunidade discutindo melhores pr√°ticas de uso

### Ferramentas Complementares

- **jq:** Parser JSON CLI (`sudo pacman -S jq`)

- **bat:** Visualizar JSON colorido (`bat file.json`)

- **fd:** Buscar arquivos transcri√ß√µes (`fd .json transcricoes/`)

- **ripgrep:** Buscar em m√∫ltiplos JSONs (`rg "pend√™ncia cr√≠tica" transcricoes/`)

---

## üí° Dicas Disruptivas

### Otimiza√ß√£o Performance

```bash

# Paralelizar 5 capta√ß√µes (GNU Parallel)

parallel -j 5 node scrape.js :::: links.txt

# Cache DNS (reduz lat√™ncia)

export NODE_OPTIONS="--dns-result-order=ipv4first"

```text

### Detec√ß√£o de Mudan√ßas

```bash

# Captar mesma conversa 2x, ver diff

node scrape.js "link" > v1.txt
sleep 3600 # 1h depois

node scrape.js "link" > v2.txt
diff v1.txt v2.txt # Grok editou algo?

```text

### Backup Autom√°tico

```bash

# Cron di√°rio: captar + backup

0 2 *

  ./scrape-batch.sh && \
  tar -czf backup-$(date +%Y%m%d).tar.gz transcricoes/ && \
  rclone copy backup-*.tar.gz remote:backups/

```text

---

## ‚úÖ Conclus√£o

**Metodologia Scrappy v2.0** √© uma framework completa para capta√ß√£o contextual inteligente de conversas Grok. Diferencial:

1. **Preserva 100% contexto humano** - Sentimentos, corre√ß√µes, valida√ß√µes conversacionais

2. **Detecta inconsist√™ncias** - Erros do modelo, info desatualizada

3. **Valida atualidade** - Web research autom√°tico (2025 vs modelo)

4. **Organiza√ß√£o multi-arquivo** - JSONs estruturados + MD consolidado

5. **CLI-first** - Headless, r√°pido, pipeable, paraleliz√°vel

6. **MCP-ready** - Integra com Playwright MCP se dispon√≠vel

**Pr√≥ximo passo:** Testar `scrape-batch.sh` com 5 links reais e validar JSONs gerados.

---

**DevSan | Metodologia v2.0 | 30 OUT 2025** üöÄ

